{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "Loaded Decision tree model ::  GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('vect',\n",
      "                                        CountVectorizer(analyzer='word',\n",
      "                                                        binary=False,\n",
      "                                                        decode_error='strict',\n",
      "                                                        dtype=<class 'numpy.int64'>,\n",
      "                                                        encoding='utf-8',\n",
      "                                                        input='content',\n",
      "                                                        lowercase=True,\n",
      "                                                        max_df=1.0,\n",
      "                                                        max_features=None,\n",
      "                                                        min_df=1,\n",
      "                                                        ngram_range=(1, 1),\n",
      "                                                        preprocessor=None,\n",
      "                                                        stop_words=None,\n",
      "                                                        strip_accents=None,\n",
      "                                                        token_pattern='(...\n",
      "                                                               min_samples_leaf=1,\n",
      "                                                               min_samples_split=2,\n",
      "                                                               min_weight_fraction_leaf=0.0,\n",
      "                                                               n_estimators=100,\n",
      "                                                               n_jobs=None,\n",
      "                                                               oob_score=False,\n",
      "                                                               random_state=None,\n",
      "                                                               verbose=0,\n",
      "                                                               warm_start=False))],\n",
      "                                verbose=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'clf__min_samples_split': [10],\n",
      "                         'clf__n_estimators': [100]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='accuracy', verbose=2)\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# ______Loading the saved model _______\n",
    "\n",
    "print('Loading model...\\n')\n",
    "\n",
    "decision_tree_model_pkl = open(\"C:/Users/Hp/Desktop/Precious_Model/Random_Forest_Model.pkl\", 'rb')\n",
    "decision_tree_model = pickle.load(decision_tree_model_pkl)\n",
    "print (\"Loaded Decision tree model :: \", decision_tree_model)\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you asking about javascript ?\n"
     ]
    }
   ],
   "source": [
    "q0 = \"How can I get html view !\"\n",
    "q1 = \"what are training models \"\n",
    "q2 = \"spring security\"\n",
    "\n",
    "#Add q to database !\n",
    "\n",
    "q = tokenize(q0)\n",
    "y_pred = decision_tree_model.predict(q)\n",
    "\n",
    "y_pred = [x for x in y_pred if x not in 'no_meaning']\n",
    "\n",
    "if(len(y_pred) == 0):\n",
    "    y_pred = 'no_meaning! ' + '\\n' + 'reformulate your question'\n",
    "else:\n",
    "    y_pred = 'Are you asking about' + ' ' + y_pred[0] + ' ' + '?'\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "#Add y_pred to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
